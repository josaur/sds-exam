{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162471d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "REPLICATION: Modeling Spatial Heterogeneity and Historical Persistence\n",
      "Nazi Concentration Camps and Contemporary Intolerance\n",
      "Pepinsky, Goodman, and Ziller (2023)\n",
      "======================================================================\n",
      "======================================================================\n",
      "Loading and preparing data...\n",
      "======================================================================\n",
      "\n",
      "Mean intolerance by state:\n",
      "                              intolerance      \n",
      "                                     mean count\n",
      "state_name                                     \n",
      "EAST:\\nBerlin                       0.257    58\n",
      "EAST:\\nBrandenburg                  0.178   205\n",
      "EAST:\\nMecklenburg-Vorpommern       0.073   102\n",
      "EAST:\\nSaxony                       0.206   314\n",
      "EAST:\\nSaxony-Anhalt                0.343   212\n",
      "EAST:\\nThuringia                    0.073   135\n",
      "WEST:\\nBaden-Wurttemberg            0.029   180\n",
      "WEST:\\nBavaria                      0.371   186\n",
      "WEST:\\nBremen                      -0.134    17\n",
      "WEST:\\nHamburg                      0.072    30\n",
      "WEST:\\nHessen                      -0.016    92\n",
      "WEST:\\nLower Saxony                 0.113   135\n",
      "WEST:\\nNorth Rhine-Westphalia      -0.015   301\n",
      "WEST:\\nRhineland Palatinate         0.007    37\n",
      "WEST:\\nSaarland                     0.238    20\n",
      "WEST:\\nSchleswig-Holstein          -0.016    51\n",
      "\n",
      "Distance categories by state:\n",
      "DistanceCat                    first  second  third  fourth  fifth\n",
      "state_name                                                        \n",
      "EAST:\\nBerlin                     58       0      0       0      0\n",
      "EAST:\\nBrandenburg                35      84     22      64      0\n",
      "EAST:\\nMecklenburg-Vorpommern     12      17     46      27      0\n",
      "EAST:\\nSaxony                      0      21    152      33    108\n",
      "EAST:\\nSaxony-Anhalt              71      96     45       0      0\n",
      "EAST:\\nThuringia                  78      57      0       0      0\n",
      "WEST:\\nBaden-Wurttemberg           0       0     28      50    102\n",
      "WEST:\\nBavaria                    54      72     20      40      0\n",
      "WEST:\\nBremen                      0       0     17       0      0\n",
      "WEST:\\nHamburg                    30       0      0       0      0\n",
      "WEST:\\nHessen                      0       0     41      51      0\n",
      "WEST:\\nLower Saxony               81      29      0      21      4\n",
      "WEST:\\nNorth Rhine-Westphalia      0       0     17      91    193\n",
      "WEST:\\nRhineland Palatinate        0      11      9      17      0\n",
      "WEST:\\nSaarland                    3      17      0       0      0\n",
      "WEST:\\nSchleswig-Holstein          0      11     27      13      0\n",
      "\n",
      "======================================================================\n",
      "TABLE 1: European Values Survey Analysis\n",
      "======================================================================\n",
      "\n",
      "--- Panel: Intolerance ---\n",
      "  Bootstrapping G-estimator SEs (no FE)...\n",
      "  Bootstrapping G-estimator SEs (with FE)...\n",
      "\n",
      "  Results for Intolerance:\n",
      "  Model                  Distance Coef           SE      p-value\n",
      "  ------------------------------------------------------------\n",
      "  Bivariate                   -0.0087**       0.0027       0.0013\n",
      "  Bivariate + FE               0.0038       0.0043       0.3792\n",
      "  Pre-treatment               -0.0112**       0.0029       0.0001\n",
      "  Pre-treatment + FE           0.0011       0.0043       0.7992\n",
      "  G-estimator                 -0.0166**       0.0039       0.0000\n",
      "  G-estimator + FE             0.0054       0.0930       0.9535\n",
      "\n",
      "--- Panel: Resentment ---\n",
      "  Bootstrapping G-estimator SEs (no FE)...\n",
      "  Bootstrapping G-estimator SEs (with FE)...\n",
      "\n",
      "  Results for Resentment:\n",
      "  Model                  Distance Coef           SE      p-value\n",
      "  ------------------------------------------------------------\n",
      "  Bivariate                   -0.1062**       0.0159       0.0000\n",
      "  Bivariate + FE              -0.0286       0.0251       0.2543\n",
      "  Pre-treatment               -0.1162**       0.0171       0.0000\n",
      "  Pre-treatment + FE          -0.0408       0.0252       0.1058\n",
      "  G-estimator                 -0.1056**       0.0211       0.0000\n",
      "  G-estimator + FE            -0.0181       0.5008       0.9712\n",
      "\n",
      "--- Panel: Far-Right Support ---\n",
      "  Bootstrapping G-estimator SEs (no FE)...\n",
      "  Bootstrapping G-estimator SEs (with FE)...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Python translation of analysis.R\n",
    "Replication code for: \"Modeling Spatial Heterogeneity and Historical Persistence:\n",
    "Nazi Concentration Camps and Contemporary Intolerance\"\n",
    "\n",
    "Required packages: pandas, numpy, statsmodels, scipy\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Note: We implement panel data methods manually instead of using linearmodels\n",
    "# to ensure portability and avoid package installation issues.\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(12435)\n",
    "\n",
    "# ============================================================================\n",
    "# Configuration - Set your data path here\n",
    "# ============================================================================\n",
    "\n",
    "DATA_PATH = \"../exam/data/replication_archive/tables/\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "def get_robust_se(model):\n",
    "    \"\"\"Get heteroskedasticity-robust standard errors.\"\"\"\n",
    "    return model.HC1_se\n",
    "\n",
    "\n",
    "def create_state_dummies(df, state_col='state'):\n",
    "    \"\"\"Create dummy variables for states (fixed effects).\"\"\"\n",
    "    return pd.get_dummies(df[state_col], prefix='state', drop_first=True)\n",
    "\n",
    "\n",
    "def hausman_test(fe_model, re_model):\n",
    "    \"\"\"\n",
    "    Perform Hausman specification test.\n",
    "    \n",
    "    H0: Random effects is consistent and efficient\n",
    "    H1: Fixed effects is consistent, random effects is not\n",
    "    \n",
    "    Returns p-value\n",
    "    \"\"\"\n",
    "    # Get coefficients (excluding constant/intercept)\n",
    "    b_fe = fe_model.params\n",
    "    b_re = re_model.params\n",
    "    \n",
    "    # Get common coefficients\n",
    "    common_coefs = b_fe.index.intersection(b_re.index)\n",
    "    common_coefs = [c for c in common_coefs if c != 'const' and c != 'Intercept' and not c.startswith('state') and not c.startswith('C(')]\n",
    "    \n",
    "    if len(common_coefs) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    b_fe = b_fe[common_coefs]\n",
    "    b_re = b_re[common_coefs]\n",
    "    \n",
    "    # Get variance-covariance matrices\n",
    "    try:\n",
    "        v_fe = fe_model.cov_params().loc[common_coefs, common_coefs]\n",
    "        v_re = re_model.cov_params().loc[common_coefs, common_coefs]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    # Hausman statistic\n",
    "    diff = b_fe - b_re\n",
    "    v_diff = v_fe - v_re\n",
    "    \n",
    "    try:\n",
    "        chi2 = float(diff.T @ np.linalg.inv(v_diff) @ diff)\n",
    "        df = len(common_coefs)\n",
    "        p_value = 1 - stats.chi2.cdf(chi2, df)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # If matrix is singular, return NaN\n",
    "        p_value = np.nan\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "\n",
    "def panel_fe_model(data, formula, group_var):\n",
    "    \"\"\"\n",
    "    Estimate a fixed effects (within) panel model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Panel data\n",
    "    formula : str\n",
    "        Model formula (without fixed effects)\n",
    "    group_var : str\n",
    "        Variable name for panel groups\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Fitted model object\n",
    "    \"\"\"\n",
    "    # Add fixed effects to formula\n",
    "    fe_formula = f\"{formula} + C({group_var})\"\n",
    "    return smf.ols(fe_formula, data=data).fit()\n",
    "\n",
    "\n",
    "def panel_re_model(data, formula, group_var):\n",
    "    \"\"\"\n",
    "    Estimate a random effects panel model using GLS.\n",
    "    \n",
    "    This is a simplified implementation using between/within decomposition.\n",
    "    For full random effects, consider using linearmodels package.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Panel data\n",
    "    formula : str\n",
    "        Model formula\n",
    "    group_var : str\n",
    "        Variable name for panel groups\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Fitted model object (approximation using partial pooling)\n",
    "    \"\"\"\n",
    "    # For simplicity, we use a between-within mixed approach\n",
    "    # In practice, you'd want to use linearmodels.panel.RandomEffects\n",
    "    \n",
    "    # Parse formula\n",
    "    parts = formula.split('~')\n",
    "    y_var = parts[0].strip()\n",
    "    x_vars = [x.strip() for x in parts[1].split('+')]\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    # Calculate group means\n",
    "    for var in [y_var] + x_vars:\n",
    "        if var in df.columns:\n",
    "            df[f'{var}_mean'] = df.groupby(group_var)[var].transform('mean')\n",
    "            df[f'{var}_demean'] = df[var] - df[f'{var}_mean']\n",
    "    \n",
    "    # Random effects uses a weighted combination\n",
    "    # For simplicity, return pooled OLS (which is close to RE when between variance is high)\n",
    "    return smf.ols(formula, data=data).fit()\n",
    "\n",
    "\n",
    "def panel_pooled_model(data, formula):\n",
    "    \"\"\"\n",
    "    Estimate a pooled OLS model (ignoring panel structure).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Panel data\n",
    "    formula : str\n",
    "        Model formula\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Fitted model object\n",
    "    \"\"\"\n",
    "    return smf.ols(formula, data=data).fit()\n",
    "\n",
    "\n",
    "def g_estimator_second_stage(df, outcome, first_stage_coefs, \n",
    "                              pretreatment_vars, mediator_vars):\n",
    "    \"\"\"\n",
    "    Compute the second stage of the sequential G-estimator.\n",
    "    \n",
    "    This removes the effect of mediators from the outcome and regresses\n",
    "    on pre-treatment variables only.\n",
    "    \"\"\"\n",
    "    # Compute adjusted outcome\n",
    "    y_adjusted = df[outcome].copy()\n",
    "    for var in mediator_vars:\n",
    "        if var in first_stage_coefs.index:\n",
    "            y_adjusted = y_adjusted - first_stage_coefs[var] * df[var]\n",
    "    \n",
    "    # Regress adjusted outcome on pre-treatment variables\n",
    "    X = sm.add_constant(df[pretreatment_vars])\n",
    "    model = OLS(y_adjusted, X, missing='drop').fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def bootstrap_g_estimator(df, outcome, pretreatment_vars, posttreatment_vars,\n",
    "                          mediator_vars, fe_var=None, n_boots=1000, seed=543):\n",
    "    \"\"\"\n",
    "    Bootstrap the sequential G-estimator to get standard errors.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        The data\n",
    "    outcome : str\n",
    "        Outcome variable name\n",
    "    pretreatment_vars : list\n",
    "        List of pre-treatment control variable names\n",
    "    posttreatment_vars : list\n",
    "        List of all post-treatment control variable names (including mediators)\n",
    "    mediator_vars : list\n",
    "        List of mediator variable names (subset of posttreatment_vars)\n",
    "    fe_var : str, optional\n",
    "        Variable for fixed effects\n",
    "    n_boots : int\n",
    "        Number of bootstrap iterations\n",
    "    seed : int\n",
    "        Random seed\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    coefs : array\n",
    "        Point estimates from original data\n",
    "    ses : array\n",
    "        Bootstrap standard errors\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Clean data\n",
    "    all_vars = [outcome] + pretreatment_vars + posttreatment_vars\n",
    "    if fe_var:\n",
    "        all_vars.append(fe_var)\n",
    "    df_clean = df[all_vars].dropna()\n",
    "    \n",
    "    n = len(df_clean)\n",
    "    \n",
    "    # Determine number of coefficients\n",
    "    if fe_var:\n",
    "        n_fe = df_clean[fe_var].nunique() - 1\n",
    "        n_coefs = len(pretreatment_vars) + 1 + n_fe  # +1 for intercept\n",
    "    else:\n",
    "        n_coefs = len(pretreatment_vars) + 1\n",
    "    \n",
    "    boot_coefs = np.zeros((n_boots, n_coefs))\n",
    "    \n",
    "    for b in range(n_boots):\n",
    "        # Bootstrap sample\n",
    "        idx = np.random.choice(n, size=n, replace=True)\n",
    "        d_star = df_clean.iloc[idx].reset_index(drop=True)\n",
    "        \n",
    "        try:\n",
    "            # First stage: full model with all controls\n",
    "            if fe_var:\n",
    "                formula = f\"{outcome} ~ {' + '.join(pretreatment_vars)} + C({fe_var}) + {' + '.join(posttreatment_vars)}\"\n",
    "            else:\n",
    "                formula = f\"{outcome} ~ {' + '.join(pretreatment_vars)} + {' + '.join(posttreatment_vars)}\"\n",
    "            \n",
    "            first_stage = smf.ols(formula, data=d_star).fit()\n",
    "            \n",
    "            # Second stage: adjusted outcome on pre-treatment vars\n",
    "            y_adjusted = d_star[outcome].copy()\n",
    "            for var in mediator_vars:\n",
    "                if var in first_stage.params.index:\n",
    "                    y_adjusted = y_adjusted - first_stage.params[var] * d_star[var]\n",
    "            \n",
    "            if fe_var:\n",
    "                formula2 = f\"y_adjusted ~ {' + '.join(pretreatment_vars)} + C({fe_var})\"\n",
    "            else:\n",
    "                formula2 = f\"y_adjusted ~ {' + '.join(pretreatment_vars)}\"\n",
    "            \n",
    "            d_star['y_adjusted'] = y_adjusted\n",
    "            second_stage = smf.ols(formula2, data=d_star).fit()\n",
    "            \n",
    "            # Store coefficients (first n_coefs)\n",
    "            boot_coefs[b, :min(n_coefs, len(second_stage.params))] = second_stage.params.values[:min(n_coefs, len(second_stage.params))]\n",
    "            \n",
    "        except Exception as e:\n",
    "            boot_coefs[b, :] = np.nan\n",
    "    \n",
    "    # Remove failed bootstrap iterations\n",
    "    boot_coefs = boot_coefs[~np.isnan(boot_coefs).any(axis=1)]\n",
    "    \n",
    "    # Get SEs as SD of bootstrap distribution\n",
    "    ses = np.std(boot_coefs, axis=0)\n",
    "    \n",
    "    return ses\n",
    "\n",
    "\n",
    "def estimate_iwe(y, treatment, group, controls, data):\n",
    "    \"\"\"\n",
    "    Estimate the Interaction-Weighted Estimator (IWE) from Gibbons et al. (2019).\n",
    "    \n",
    "    This estimates heterogeneous treatment effects by group and then\n",
    "    computes a precision-weighted average.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y : str\n",
    "        Outcome variable name\n",
    "    treatment : str\n",
    "        Treatment variable name\n",
    "    group : str\n",
    "        Group variable name for fixed effects\n",
    "    controls : list\n",
    "        List of control variable names\n",
    "    data : DataFrame\n",
    "        The data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with:\n",
    "        - swe_est: Sample-weighted estimate\n",
    "        - swe_var: Variance of sample-weighted estimate\n",
    "        - fe_est: Standard FE estimate\n",
    "        - fe_var: Variance of FE estimate\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Get unique groups\n",
    "    groups = df[group].unique()\n",
    "    n_groups = len(groups)\n",
    "    \n",
    "    # Demean within groups (equivalent to FE transformation)\n",
    "    for col in [y, treatment] + controls:\n",
    "        group_means = df.groupby(group)[col].transform('mean')\n",
    "        df[f'{col}_dm'] = df[col] - group_means\n",
    "    \n",
    "    # Standard FE estimate\n",
    "    X_fe = sm.add_constant(df[[f'{treatment}_dm'] + [f'{c}_dm' for c in controls]])\n",
    "    y_fe = df[f'{y}_dm']\n",
    "    fe_model = OLS(y_fe, X_fe, missing='drop').fit(cov_type='HC1')\n",
    "    fe_est = fe_model.params[f'{treatment}_dm']\n",
    "    fe_var = fe_model.HC1_se[f'{treatment}_dm'] ** 2\n",
    "    \n",
    "    # Group-specific estimates\n",
    "    group_ests = []\n",
    "    group_vars = []\n",
    "    group_weights = []\n",
    "    \n",
    "    for g in groups:\n",
    "        df_g = df[df[group] == g]\n",
    "        if len(df_g) < len(controls) + 3:  # Need enough observations\n",
    "            continue\n",
    "        \n",
    "        # Check for variation in treatment\n",
    "        if df_g[treatment].std() < 1e-10:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            X_g = sm.add_constant(df_g[[treatment] + controls])\n",
    "            y_g = df_g[y]\n",
    "            model_g = OLS(y_g, X_g, missing='drop').fit(cov_type='HC1')\n",
    "            \n",
    "            est_g = model_g.params[treatment]\n",
    "            var_g = model_g.HC1_se[treatment] ** 2\n",
    "            \n",
    "            # Weight = 1/variance (precision weighting)\n",
    "            if var_g > 0:\n",
    "                group_ests.append(est_g)\n",
    "                group_vars.append(var_g)\n",
    "                group_weights.append(1 / var_g)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(group_ests) == 0:\n",
    "        return {'swe_est': np.nan, 'swe_var': np.nan, 'fe_est': fe_est, 'fe_var': fe_var}\n",
    "    \n",
    "    # Precision-weighted average\n",
    "    total_weight = sum(group_weights)\n",
    "    swe_est = sum(w * e for w, e in zip(group_weights, group_ests)) / total_weight\n",
    "    \n",
    "    # Variance of weighted average\n",
    "    swe_var = 1 / total_weight\n",
    "    \n",
    "    return {\n",
    "        'swe_est': swe_est,\n",
    "        'swe_var': swe_var,\n",
    "        'fe_est': fe_est,\n",
    "        'fe_var': fe_var\n",
    "    }\n",
    "\n",
    "\n",
    "def estimate_rwe(y, treatment, group, controls, data):\n",
    "    \"\"\"\n",
    "    Estimate the Regression-Weighted Estimator (RWE) from Gibbons et al. (2019).\n",
    "    \n",
    "    This uses regression weights based on within-group treatment variation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y : str\n",
    "        Outcome variable name\n",
    "    treatment : str\n",
    "        Treatment variable name\n",
    "    group : str\n",
    "        Group variable name for fixed effects\n",
    "    controls : list\n",
    "        List of control variable names\n",
    "    data : DataFrame\n",
    "        The data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with:\n",
    "        - swe_est: Sample-weighted estimate\n",
    "        - swe_var: Variance of sample-weighted estimate\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Get unique groups\n",
    "    groups = df[group].unique()\n",
    "    \n",
    "    # Group-specific estimates with size weights\n",
    "    group_ests = []\n",
    "    group_vars = []\n",
    "    group_weights = []\n",
    "    \n",
    "    for g in groups:\n",
    "        df_g = df[df[group] == g]\n",
    "        n_g = len(df_g)\n",
    "        \n",
    "        if n_g < len(controls) + 3:\n",
    "            continue\n",
    "        \n",
    "        # Check for variation in treatment\n",
    "        treat_var = df_g[treatment].var()\n",
    "        if treat_var < 1e-10:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            X_g = sm.add_constant(df_g[[treatment] + controls])\n",
    "            y_g = df_g[y]\n",
    "            model_g = OLS(y_g, X_g, missing='drop').fit(cov_type='HC1')\n",
    "            \n",
    "            est_g = model_g.params[treatment]\n",
    "            var_g = model_g.HC1_se[treatment] ** 2\n",
    "            \n",
    "            # Weight = n_g * Var(treatment within group)\n",
    "            weight = n_g * treat_var\n",
    "            \n",
    "            group_ests.append(est_g)\n",
    "            group_vars.append(var_g)\n",
    "            group_weights.append(weight)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if len(group_ests) == 0:\n",
    "        return {'swe_est': np.nan, 'swe_var': np.nan}\n",
    "    \n",
    "    # Regression-weighted average\n",
    "    total_weight = sum(group_weights)\n",
    "    swe_est = sum(w * e for w, e in zip(group_weights, group_ests)) / total_weight\n",
    "    \n",
    "    # Variance (approximate)\n",
    "    swe_var = sum((w/total_weight)**2 * v for w, v in zip(group_weights, group_vars))\n",
    "    \n",
    "    return {\n",
    "        'swe_est': swe_est,\n",
    "        'swe_var': swe_var\n",
    "    }\n",
    "\n",
    "\n",
    "def format_results_table(models, model_names, coef_names, custom_ses=None):\n",
    "    \"\"\"\n",
    "    Format regression results into a table similar to stargazer output.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : list\n",
    "        List of fitted model objects\n",
    "    model_names : list\n",
    "        Names for each model column\n",
    "    coef_names : list\n",
    "        Names of coefficients to include\n",
    "    custom_ses : list, optional\n",
    "        List of custom standard errors for each model (None to use model SEs)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with formatted results\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for var in coef_names:\n",
    "        row_coef = {'Variable': var}\n",
    "        row_se = {'Variable': f'({var} SE)'}\n",
    "        \n",
    "        for i, (model, name) in enumerate(zip(models, model_names)):\n",
    "            try:\n",
    "                coef = model.params.get(var, np.nan)\n",
    "                if custom_ses and custom_ses[i] is not None:\n",
    "                    se = custom_ses[i].get(var, np.nan) if isinstance(custom_ses[i], dict) else custom_ses[i][coef_names.index(var)]\n",
    "                else:\n",
    "                    se = model.bse.get(var, np.nan)\n",
    "                \n",
    "                # Significance stars\n",
    "                if not np.isnan(coef) and not np.isnan(se):\n",
    "                    t_stat = abs(coef / se)\n",
    "                    if t_stat > 2.576:\n",
    "                        stars = '**'\n",
    "                    elif t_stat > 1.96:\n",
    "                        stars = '*'\n",
    "                    else:\n",
    "                        stars = ''\n",
    "                    row_coef[name] = f'{coef:.3f}{stars}'\n",
    "                    row_se[name] = f'({se:.3f})'\n",
    "                else:\n",
    "                    row_coef[name] = ''\n",
    "                    row_se[name] = ''\n",
    "            except:\n",
    "                row_coef[name] = ''\n",
    "                row_se[name] = ''\n",
    "        \n",
    "        results.append(row_coef)\n",
    "        results.append(row_se)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Data Loading and Preparation\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_prep_data():\n",
    "    \"\"\"Load and prepare all datasets.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"Loading and preparing data...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load main EVS data\n",
    "    evs = pd.read_csv(f'{DATA_PATH}/EVS_main.csv')\n",
    "    \n",
    "    # Create factor for state\n",
    "    evs['f_state'] = evs['state'].astype('category')\n",
    "    \n",
    "    # Recode state names\n",
    "    state_recode = {\n",
    "        'DE1': 'WEST:\\nBaden-Wurttemberg',\n",
    "        'DE2': 'WEST:\\nBavaria',\n",
    "        'DE3': 'EAST:\\nBerlin',\n",
    "        'DE4': 'EAST:\\nBrandenburg',\n",
    "        'DE5': 'WEST:\\nBremen',\n",
    "        'DE6': 'WEST:\\nHamburg',\n",
    "        'DE7': 'WEST:\\nHessen',\n",
    "        'DE8': 'EAST:\\nMecklenburg-Vorpommern',\n",
    "        'DE9': 'WEST:\\nLower Saxony',\n",
    "        'DEA': 'WEST:\\nNorth Rhine-Westphalia',\n",
    "        'DEB': 'WEST:\\nRhineland Palatinate',\n",
    "        'DEC': 'WEST:\\nSaarland',\n",
    "        'DED': 'EAST:\\nSaxony',\n",
    "        'DEE': 'EAST:\\nSaxony-Anhalt',\n",
    "        'DEF': 'WEST:\\nSchleswig-Holstein',\n",
    "        'DEG': 'EAST:\\nThuringia'\n",
    "    }\n",
    "    evs['state_name'] = evs['state'].map(state_recode)\n",
    "    \n",
    "    # Summary statistics by state\n",
    "    print(\"\\nMean intolerance by state:\")\n",
    "    print(evs.groupby('state_name').agg({'intolerance': ['mean', 'count']}).round(3))\n",
    "    \n",
    "    # Create distance categories\n",
    "    evs['DistanceCat'] = pd.qcut(evs['Distance'], q=5, \n",
    "                                  labels=['first', 'second', 'third', 'fourth', 'fifth'])\n",
    "    \n",
    "    print(\"\\nDistance categories by state:\")\n",
    "    print(pd.crosstab(evs['state_name'], evs['DistanceCat']))\n",
    "    \n",
    "    # Load EVS with Weimar-era boundaries\n",
    "    evs_weimar = pd.read_csv(f'{DATA_PATH}/evs_weimar.csv')\n",
    "    evs_weimar['Distance'] = evs_weimar['distance']\n",
    "    \n",
    "    # Create Weimar province fixed effects\n",
    "    evs_weimar.loc[evs_weimar['oldland_pruprov'] == 2000, 'oldland_pruprov'] = 2001\n",
    "    evs_weimar['weimarprov'] = evs_weimar['oldland'].copy()\n",
    "    mask = evs_weimar['weimarprov'] == 1000\n",
    "    evs_weimar.loc[mask, 'weimarprov'] = evs_weimar.loc[mask, 'oldland_pruprov']\n",
    "    \n",
    "    # Load 2017 election data\n",
    "    elect_data = pd.read_csv(f'{DATA_PATH}/elections_2017.csv')\n",
    "    \n",
    "    # Remove states with no internal variation in Distance for reweighting\n",
    "    elect_data_bfe = elect_data[~elect_data['NAME_1'].isin(['Berlin', 'Hamburg'])].copy()\n",
    "    \n",
    "    return evs, evs_weimar, elect_data, elect_data_bfe\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Table 1: Main EVS Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def run_table1_analysis(evs):\n",
    "    \"\"\"\n",
    "    Run Table 1 analysis: EVS data with intolerance, resentment, and far-right outcomes.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TABLE 1: European Values Survey Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Define variables\n",
    "    pretreatment_vars = ['Distance', 'prop_jewish25', 'unemployment33', 'population25', 'nazishare33']\n",
    "    posttreatment_vars = ['lr', 'immigrants07', 'unemployment07', 'unemp', 'educ', \n",
    "                          'female', 'age', 'urban_scale', 'west']\n",
    "    mediator_vars = ['immigrants07', 'lr', 'unemp', 'unemployment07', 'educ', 'urban_scale']\n",
    "    \n",
    "    outcomes = ['intolerance', 'resentment', 'far_right']\n",
    "    outcome_names = ['Intolerance', 'Resentment', 'Far-Right Support']\n",
    "    \n",
    "    results_all = {}\n",
    "    \n",
    "    for outcome, outcome_name in zip(outcomes, outcome_names):\n",
    "        print(f\"\\n--- Panel: {outcome_name} ---\")\n",
    "        \n",
    "        # Model 1: Bivariate\n",
    "        m_biv = smf.ols(f'{outcome} ~ Distance', data=evs).fit()\n",
    "        \n",
    "        # Model 2: Bivariate with FE\n",
    "        m_biv_fe = smf.ols(f'{outcome} ~ Distance + C(state)', data=evs).fit()\n",
    "        \n",
    "        # Model 3: With pre-treatment controls\n",
    "        formula_pre = f'{outcome} ~ Distance + prop_jewish25 + unemployment33 + population25 + nazishare33'\n",
    "        m_pre = smf.ols(formula_pre, data=evs).fit()\n",
    "        \n",
    "        # Model 4: Pre-treatment with FE\n",
    "        m_pre_fe = smf.ols(f'{formula_pre} + C(state)', data=evs).fit()\n",
    "        \n",
    "        # Model 5: G-estimator (no FE)\n",
    "        formula_full = f'{outcome} ~ Distance + prop_jewish25 + unemployment33 + population25 + nazishare33 + ' + \\\n",
    "                       'lr + immigrants07 + unemployment07 + unemp + educ + female + age + urban_scale + west'\n",
    "        m_full = smf.ols(formula_full, data=evs).fit()\n",
    "        \n",
    "        # Second stage of G-estimator\n",
    "        evs_temp = evs.copy()\n",
    "        y_adj = evs_temp[outcome].copy()\n",
    "        for var in mediator_vars:\n",
    "            if var in m_full.params.index:\n",
    "                y_adj = y_adj - m_full.params[var] * evs_temp[var]\n",
    "        evs_temp['y_adjusted'] = y_adj\n",
    "        m_gest = smf.ols('y_adjusted ~ Distance + prop_jewish25 + unemployment33 + population25 + nazishare33', \n",
    "                         data=evs_temp).fit()\n",
    "        \n",
    "        # Bootstrap SEs for G-estimator\n",
    "        print(f\"  Bootstrapping G-estimator SEs (no FE)...\")\n",
    "        ses_gest = bootstrap_g_estimator(evs, outcome, pretreatment_vars, posttreatment_vars, \n",
    "                                         mediator_vars, fe_var=None, n_boots=1000, seed=543)\n",
    "        \n",
    "        # Model 6: G-estimator with FE\n",
    "        m_full_fe = smf.ols(f'{formula_full} + C(state)', data=evs).fit()\n",
    "        \n",
    "        y_adj_fe = evs_temp[outcome].copy()\n",
    "        for var in mediator_vars:\n",
    "            if var in m_full_fe.params.index:\n",
    "                y_adj_fe = y_adj_fe - m_full_fe.params[var] * evs_temp[var]\n",
    "        evs_temp['y_adjusted_fe'] = y_adj_fe\n",
    "        m_gest_fe = smf.ols('y_adjusted_fe ~ Distance + prop_jewish25 + unemployment33 + population25 + nazishare33 + C(state)', \n",
    "                            data=evs_temp).fit()\n",
    "        \n",
    "        print(f\"  Bootstrapping G-estimator SEs (with FE)...\")\n",
    "        ses_gest_fe = bootstrap_g_estimator(evs, outcome, pretreatment_vars, posttreatment_vars, \n",
    "                                            mediator_vars, fe_var='state', n_boots=1000, seed=543)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n  Results for {outcome_name}:\")\n",
    "        print(f\"  {'Model':<20} {'Distance Coef':>15} {'SE':>12} {'p-value':>12}\")\n",
    "        print(f\"  {'-'*60}\")\n",
    "        \n",
    "        models_info = [\n",
    "            ('Bivariate', m_biv, None),\n",
    "            ('Bivariate + FE', m_biv_fe, None),\n",
    "            ('Pre-treatment', m_pre, None),\n",
    "            ('Pre-treatment + FE', m_pre_fe, None),\n",
    "            ('G-estimator', m_gest, ses_gest[1] if len(ses_gest) > 1 else None),\n",
    "            ('G-estimator + FE', m_gest_fe, ses_gest_fe[1] if len(ses_gest_fe) > 1 else None),\n",
    "        ]\n",
    "        \n",
    "        for name, model, custom_se in models_info:\n",
    "            coef = model.params.get('Distance', np.nan)\n",
    "            se = custom_se if custom_se else model.bse.get('Distance', np.nan)\n",
    "            pval = 2 * (1 - stats.t.cdf(abs(coef/se), model.df_resid)) if se else np.nan\n",
    "            sig = '**' if pval < 0.01 else ('*' if pval < 0.05 else '')\n",
    "            print(f\"  {name:<20} {coef:>14.4f}{sig} {se:>12.4f} {pval:>12.4f}\")\n",
    "        \n",
    "        results_all[outcome] = {\n",
    "            'bivariate': m_biv,\n",
    "            'bivariate_fe': m_biv_fe,\n",
    "            'pretreatment': m_pre,\n",
    "            'pretreatment_fe': m_pre_fe,\n",
    "            'g_estimator': m_gest,\n",
    "            'g_estimator_fe': m_gest_fe,\n",
    "            'ses_gest': ses_gest,\n",
    "            'ses_gest_fe': ses_gest_fe\n",
    "        }\n",
    "    \n",
    "    return results_all\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Table A2: Hausman Tests\n",
    "# ============================================================================\n",
    "\n",
    "def run_hausman_tests(evs):\n",
    "    \"\"\"\n",
    "    Run Hausman specification tests comparing pooled, RE, and FE models.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TABLE A2: Hausman Specification Tests\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    outcomes = ['intolerance', 'resentment', 'far_right']\n",
    "    \n",
    "    # Bivariate models\n",
    "    print(\"\\n--- Panel A: Bivariate Models ---\")\n",
    "    print(f\"{'Outcome':<15} {'RE vs Pooled':>15} {'FE vs Pooled':>15} {'FE vs RE':>15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            formula = f'{outcome} ~ Distance'\n",
    "            \n",
    "            # Pooled OLS\n",
    "            pooled = panel_pooled_model(evs, formula)\n",
    "            # Random Effects (approximated)\n",
    "            re = panel_re_model(evs, formula, 'state')\n",
    "            # Fixed Effects\n",
    "            fe = panel_fe_model(evs, formula, 'state')\n",
    "            \n",
    "            # Hausman tests\n",
    "            re_v_pooled = hausman_test(re, pooled)\n",
    "            fe_v_pooled = hausman_test(fe, pooled)\n",
    "            fe_v_re = hausman_test(fe, re)\n",
    "            \n",
    "            print(f\"{outcome:<15} {re_v_pooled:>15.3f} {fe_v_pooled:>15.3f} {fe_v_re:>15.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{outcome:<15} {'Error':>15} {'Error':>15} {'Error':>15}\")\n",
    "    \n",
    "    # With prewar controls\n",
    "    print(\"\\n--- Panel B: With Prewar Controls ---\")\n",
    "    print(f\"{'Outcome':<15} {'RE vs Pooled':>15} {'FE vs Pooled':>15} {'FE vs RE':>15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    controls = 'Distance + prop_jewish25 + unemployment33 + population25 + nazishare33'\n",
    "    \n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            formula = f'{outcome} ~ {controls}'\n",
    "            \n",
    "            pooled = panel_pooled_model(evs, formula)\n",
    "            re = panel_re_model(evs, formula, 'state')\n",
    "            fe = panel_fe_model(evs, formula, 'state')\n",
    "            \n",
    "            re_v_pooled = hausman_test(re, pooled)\n",
    "            fe_v_pooled = hausman_test(fe, pooled)\n",
    "            fe_v_re = hausman_test(fe, re)\n",
    "            \n",
    "            print(f\"{outcome:<15} {re_v_pooled:>15.3f} {fe_v_pooled:>15.3f} {fe_v_re:>15.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{outcome:<15} {'Error':>15} {'Error':>15} {'Error':>15}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Table A3: Reweighted Analyses\n",
    "# ============================================================================\n",
    "\n",
    "def run_reweighted_analysis(evs):\n",
    "    \"\"\"\n",
    "    Run reweighted analyses using IWE and RWE estimators.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TABLE A3: Reweighted Analyses (IWE and RWE)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Exclude states with no variation in Distance (Berlin and Hamburg)\n",
    "    data_evs = evs[~evs['f_state'].isin(['DE3', 'DE6'])].copy()\n",
    "    \n",
    "    controls = ['prop_jewish25', 'unemployment33', 'population25', 'nazishare33']\n",
    "    outcomes = ['intolerance', 'resentment', 'far_right']\n",
    "    outcome_names = ['Intolerance', 'Resentment', 'Far-Right Support']\n",
    "    \n",
    "    print(f\"\\n{'Outcome':<15} {'Pooled':>12} {'FE':>12} {'IWE':>12} {'RWE':>12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for outcome, outcome_name in zip(outcomes, outcome_names):\n",
    "        # Pooled OLS\n",
    "        formula = f'{outcome} ~ Distance + ' + ' + '.join(controls)\n",
    "        m_pooled = smf.ols(formula, data=data_evs).fit()\n",
    "        pooled_est = m_pooled.params['Distance']\n",
    "        \n",
    "        # Fixed Effects\n",
    "        m_fe = smf.ols(f'{formula} + C(f_state)', data=data_evs).fit()\n",
    "        fe_est = m_fe.params['Distance']\n",
    "        \n",
    "        # IWE\n",
    "        iwe_results = estimate_iwe('intolerance' if outcome == 'intolerance' else outcome, \n",
    "                                    'Distance', 'f_state', controls, data_evs)\n",
    "        iwe_est = iwe_results['swe_est']\n",
    "        \n",
    "        # RWE\n",
    "        rwe_results = estimate_rwe(outcome, 'Distance', 'f_state', controls, data_evs)\n",
    "        rwe_est = rwe_results['swe_est']\n",
    "        \n",
    "        print(f\"{outcome_name:<15} {pooled_est:>12.4f} {fe_est:>12.4f} {iwe_est:>12.4f} {rwe_est:>12.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Table 2: Election Data Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def run_election_analysis(elect_data, elect_data_bfe):\n",
    "    \"\"\"\n",
    "    Run election data analysis with Hausman tests and reweighted estimators.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TABLE 2: 2017 Bundestag Election Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    controls = ['prop_juden', 'unemp33', 'pop25', 'vshare33']\n",
    "    controls_str = ' + '.join(controls)\n",
    "    \n",
    "    outcomes = [('AfDshare', 'AfD Share'), ('AfDNPDshare', 'AfD + NPD Share')]\n",
    "    \n",
    "    for outcome, outcome_name in outcomes:\n",
    "        print(f\"\\n--- {outcome_name} ---\")\n",
    "        \n",
    "        formula = f'{outcome} ~ distance2 + {controls_str}'\n",
    "        \n",
    "        try:\n",
    "            # Pooled OLS\n",
    "            pooled = panel_pooled_model(elect_data, formula)\n",
    "            \n",
    "            # Fixed Effects\n",
    "            fe = panel_fe_model(elect_data, formula, 'NAME_1')\n",
    "            \n",
    "            print(f\"  Pooled estimate: {pooled.params['distance2']:.4f} (SE: {pooled.bse['distance2']:.4f})\")\n",
    "            print(f\"  FE estimate:     {fe.params['distance2']:.4f} (SE: {fe.bse['distance2']:.4f})\")\n",
    "            \n",
    "            # Hausman test\n",
    "            h_pval = hausman_test(fe, pooled)\n",
    "            print(f\"  Hausman test (FE vs Pooled) p-value: {h_pval:.4f}\")\n",
    "            \n",
    "            # IWE and RWE\n",
    "            iwe = estimate_iwe(outcome, 'distance2', 'NAME_1', controls, elect_data_bfe)\n",
    "            rwe = estimate_rwe(outcome, 'distance2', 'NAME_1', controls, elect_data_bfe)\n",
    "            \n",
    "            print(f\"  IWE estimate:    {iwe['swe_est']:.4f} (SE: {np.sqrt(iwe['swe_var']):.4f})\")\n",
    "            print(f\"  RWE estimate:    {rwe['swe_est']:.4f} (SE: {np.sqrt(rwe['swe_var']):.4f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Table A4: Weimar-Era Analysis\n",
    "# ============================================================================\n",
    "\n",
    "def run_weimar_analysis(evs_weimar):\n",
    "    \"\"\"\n",
    "    Run analysis using Weimar-era administrative boundaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TABLE A4: Weimar-Era LÃ¤nder Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    pretreatment_vars = ['Distance', 'prop_jewish25', 'unemployment33', 'population25', 'nazishare33']\n",
    "    posttreatment_vars = ['lr', 'immigrants07', 'unemployment07', 'unemp', 'educ', \n",
    "                          'female', 'age', 'urban_scale', 'west']\n",
    "    mediator_vars = ['immigrants07', 'lr', 'unemp', 'unemployment07', 'educ', 'urban_scale']\n",
    "    \n",
    "    outcomes = ['intolerance', 'resentment', 'far_right']\n",
    "    outcome_names = ['Intolerance', 'Resentment', 'Far-Right Support']\n",
    "    \n",
    "    for outcome, outcome_name in zip(outcomes, outcome_names):\n",
    "        print(f\"\\n--- Panel: {outcome_name} ---\")\n",
    "        \n",
    "        # Bivariate\n",
    "        m_biv = smf.ols(f'{outcome} ~ Distance', data=evs_weimar).fit()\n",
    "        \n",
    "        # Bivariate with Weimar FE\n",
    "        m_biv_fe = smf.ols(f'{outcome} ~ Distance + C(weimarprov)', data=evs_weimar).fit()\n",
    "        \n",
    "        # Pre-treatment\n",
    "        formula_pre = f'{outcome} ~ Distance + prop_jewish25 + unemployment33 + population25 + nazishare33'\n",
    "        m_pre = smf.ols(formula_pre, data=evs_weimar).fit()\n",
    "        \n",
    "        # Pre-treatment with FE\n",
    "        m_pre_fe = smf.ols(f'{formula_pre} + C(weimarprov)', data=evs_weimar).fit()\n",
    "        \n",
    "        print(f\"  {'Model':<25} {'Distance Coef':>15} {'SE':>12}\")\n",
    "        print(f\"  {'-'*55}\")\n",
    "        print(f\"  {'Bivariate':<25} {m_biv.params['Distance']:>15.4f} {m_biv.bse['Distance']:>12.4f}\")\n",
    "        print(f\"  {'Bivariate + Weimar FE':<25} {m_biv_fe.params['Distance']:>15.4f} {m_biv_fe.bse['Distance']:>12.4f}\")\n",
    "        print(f\"  {'Pre-treatment':<25} {m_pre.params['Distance']:>15.4f} {m_pre.bse['Distance']:>12.4f}\")\n",
    "        print(f\"  {'Pre-treatment + Weimar FE':<25} {m_pre_fe.params['Distance']:>15.4f} {m_pre_fe.bse['Distance']:>12.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Main Execution\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run all analyses.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"REPLICATION: Modeling Spatial Heterogeneity and Historical Persistence\")\n",
    "    print(\"Nazi Concentration Camps and Contemporary Intolerance\")\n",
    "    print(\"Pepinsky, Goodman, and Ziller (2023)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load data\n",
    "    evs, evs_weimar, elect_data, elect_data_bfe = load_and_prep_data()\n",
    "    \n",
    "    # Table 1: Main EVS analysis\n",
    "    results_table1 = run_table1_analysis(evs)\n",
    "    \n",
    "    # Table A2: Hausman tests\n",
    "    run_hausman_tests(evs)\n",
    "    \n",
    "    # Table A3: Reweighted analyses\n",
    "    run_reweighted_analysis(evs)\n",
    "    \n",
    "    # Table A4: Weimar-era analysis\n",
    "    run_weimar_analysis(evs_weimar)\n",
    "    \n",
    "    # Table 2: Election analysis\n",
    "    run_election_analysis(elect_data, elect_data_bfe)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Analysis complete!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return results_table1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
